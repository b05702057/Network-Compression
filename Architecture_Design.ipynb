{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Architecture_Design.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"8odNXcMV_wI8"},"source":["# Network Compression (Architecuture Design)"]},{"cell_type":"markdown","metadata":{"id":"SRnRXK3zQzVO"},"source":["# Model\n"]},{"cell_type":"code","metadata":{"id":"nrBEYCCC7JQP"},"source":["import torch.nn as nn\n","import torch.nn.functional as F\n","import torch\n","\n","class StudentNet(nn.Module):\n","    '''\n","      在這個Net裡面，我們會使用Depthwise & Pointwise Convolution Layer來疊model。\n","      你會發現，將原本的Convolution Layer換成Dw & Pw後，Accuracy通常不會降很多。\n","\n","      另外，取名為StudentNet是因為這個Model等會要做Knowledge Distillation。\n","    '''\n","\n","    def __init__(self, base=16, width_mult=1):\n","        '''\n","          Args:\n","            base: 這個model一開始的ch數量，每過一層都會*2，直到base*16為止。\n","            width_mult: 為了之後的Network Pruning使用，在base*8 chs的Layer上會 * width_mult代表剪枝後的ch數量。        \n","        '''\n","        super(StudentNet, self).__init__()\n","        multiplier = [1, 2, 4, 8, 16, 16, 16, 16, 4] \n","\n","        # bandwidth: 每一層Layer所使用的ch數量\n","        bandwidth = [ base * m for m in multiplier]\n","\n","        # 我們只Pruning第三層以後的Layer\n","        for i in range(3, 7):\n","            bandwidth[i] = int(bandwidth[i] * width_mult)\n","\n","        self.cnn = nn.Sequential(\n","            # 第一層我們通常不會拆解Convolution Layer（與下面那層都用bandwith[0]）。\n","            nn.Sequential(\n","                nn.Conv2d(3, bandwidth[0], 3, 1, 1), # 參數量 3 * 16 * 3^2 = 432\n","                nn.BatchNorm2d(bandwidth[0]),\n","                nn.ReLU6(),\n","                nn.MaxPool2d(2, 2, 0),\n","            ),\n","            # 接下來每一個Sequential Block都一樣，所以我們只講一個Block\n","            nn.Sequential(\n","                # Depthwise Convolution\n","                nn.Conv2d(bandwidth[0], bandwidth[0], 3, 1, 1, groups=bandwidth[0]), # 參數量 16 * 3^2 = 144\n","                # Batch Normalization\n","                nn.BatchNorm2d(bandwidth[0]),\n","                # ReLU6 是限制Neuron最小只會到0，最大只會到6。 MobileNet系列都是使用ReLU6。\n","                # 使用ReLU6的原因是因為如果數字太大，會不好壓到float16 / or further qunatization，因此才給個限制。\n","                nn.ReLU6(),\n","                # Pointwise Convolution\n","                nn.Conv2d(bandwidth[0], bandwidth[1], 1), # 參數量 16 * 32 = 512\n","                # 過完Pointwise Convolution不需要再做ReLU，經驗上Pointwise + ReLU效果都會變差。\n","                nn.MaxPool2d(2, 2, 0),\n","                # 每過完一個Block就Down Sampling\n","            ),\n","\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[1], bandwidth[1], 3, 1, 1, groups=bandwidth[1]), # 參數量 32 * 3^2 = 288\n","                nn.BatchNorm2d(bandwidth[1]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[1], bandwidth[2], 1), # 參數量 32 * 64 = 2048\n","                nn.MaxPool2d(2, 2, 0),\n","            ),\n","\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[2], bandwidth[2], 3, 1, 1, groups=bandwidth[2]), \n","                nn.BatchNorm2d(bandwidth[2]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[2], bandwidth[3], 1),\n","                nn.MaxPool2d(2, 2, 0),\n","            ),\n","\n","            # 到這邊為止因為圖片已經被Down Sample很多次了，所以就不做MaxPool\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[3], bandwidth[3], 3, 1, 1, groups=bandwidth[3]),\n","                nn.BatchNorm2d(bandwidth[3]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[3], bandwidth[4], 1),\n","            ),\n","\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[4], bandwidth[4], 3, 1, 1, groups=bandwidth[4]),\n","                nn.BatchNorm2d(bandwidth[4]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[4], bandwidth[5], 1),\n","            ),\n","\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[5], bandwidth[5], 3, 1, 1, groups=bandwidth[5]),\n","                nn.BatchNorm2d(bandwidth[5]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[5], bandwidth[6], 1),\n","            ),\n","\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[6], bandwidth[6], 3, 1, 1, groups=bandwidth[6]),\n","                nn.BatchNorm2d(bandwidth[6]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[6], bandwidth[7], 1),\n","            ),\n","            nn.Sequential(\n","                nn.Conv2d(bandwidth[7], bandwidth[7], 3, 1, 1, groups=bandwidth[7]),\n","                nn.BatchNorm2d(bandwidth[7]),\n","                nn.ReLU6(),\n","                nn.Conv2d(bandwidth[7], bandwidth[8], 1),\n","            ),\n","\n","            # 這邊我們採用Global Average Pooling。\n","            # 如果輸入不同資料集圖片大小不一樣的話，就會因為Global Average Pooling壓成一樣的形狀，這樣子接下來做FC就不會對不起來。\n","            nn.AdaptiveAvgPool2d((1, 1)), # outputsize = (1,1)\n","            # 若CNN的最後输出是h × w × d 的三维特徵圖，大小為6 × 6 × 3，經GAP轉換，變成了大小為 1 × 1 × 3 的輸出值，也就是每層 h × w 會被平均化成一个值。\n","        )\n","        self.fc = nn.Sequential(\n","            # 這邊我們直接Project到11維輸出答案。\n","            nn.Linear(bandwidth[8], 11),\n","        )\n","\n","    def forward(self, x):\n","        out = self.cnn(x)\n","        out = out.view(out.size()[0], -1)\n","        return self.fc(out)"],"execution_count":null,"outputs":[]}]}