{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Weight_Quantization.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"xXMVwO8CRbqo"},"source":["# Network Compression (Weight Quantization)\n"]},{"cell_type":"markdown","metadata":{"id":"O6PTWn7LdvMn"},"source":["# Read state_dict\n"]},{"cell_type":"code","metadata":{"id":"XRe3T_Uwd29U","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"adf09f3a-c6ff-4586-f701-5083efa55b26"},"source":["!gdown --id '12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL' --output student_custom_small.bin\n","\n","import os\n","import torch\n","\n","print(f\"\\noriginal cost: {os.stat('student_custom_small.bin').st_size} bytes.\")\n","params = torch.load('student_custom_small.bin')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Downloading...\n","From: https://drive.google.com/uc?id=12wtIa0WVRcpboQzhgRUJOpcXe23tgWUL\n","To: /content/student_custom_small.bin\n","\r  0% 0.00/1.05M [00:00<?, ?B/s]\r 50% 524k/1.05M [00:00<00:00, 3.60MB/s]\r100% 1.05M/1.05M [00:00<00:00, 4.90MB/s]\n","\n","original cost: 1047430 bytes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SXD0_G5McRGt"},"source":["# 32-bit Tensor -> 16-bit "]},{"cell_type":"code","metadata":{"id":"OIV0BzszcQg8","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"5847bc83-7df7-44f7-b9a5-a886d8027e48"},"source":["import numpy as np\n","import pickle\n","\n","def encode16(params, fname):\n","    '''將params壓縮成16-bit後輸出到fname。\n","\n","    Args:\n","      params: model的state_dict。\n","      fname: 壓縮後輸出的檔名。\n","    '''\n","\n","    custom_dict = {}\n","    for (name, param) in params.items():\n","        param = np.float64(param.cpu().numpy())\n","        # 有些東西不屬於ndarray，只是單一個數字（類型為numpy.float64），這個時候我們就不用壓縮。\n","        # 例：cnn.3.1.num_batches_tracked\n","        #    tensor(53148, device='cuda:0')\n","        if type(param) == np.ndarray:\n","            custom_dict[name] = np.float16(param)\n","        else:\n","            custom_dict[name] = param\n","\n","    pickle.dump(custom_dict, open(fname, 'wb'))\n","\n","\n","def decode16(fname):\n","    '''從fname讀取各個params，將其從16-bit還原回torch.tensor後存進state_dict內。\n","\n","    Args:\n","      fname: 壓縮後的檔名。\n","    '''\n","\n","    params = pickle.load(open(fname, 'rb'))\n","    custom_dict = {}\n","    for (name, param) in params.items():\n","        param = torch.tensor(param)\n","        custom_dict[name] = param\n","\n","    return custom_dict\n","\n","\n","encode16(params, '16_bit_model.pkl')\n","print(f\"16-bit cost: {os.stat('16_bit_model.pkl').st_size} bytes.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["16-bit cost: 522958 bytes.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Mv5PtFoWgIFb"},"source":["# 32-bit Tensor -> 8-bit "]},{"cell_type":"code","metadata":{"id":"2vh9Pn-3hZEN","colab":{"base_uri":"https://localhost:8080/","height":34},"outputId":"9e75fb98-0ea4-4ed0-b2a5-85404516a0c5"},"source":["def encode8(params, fname):\n","    custom_dict = {}\n","    for (name, param) in params.items():\n","        param = np.float64(param.cpu().numpy())\n","        if type(param) == np.ndarray:\n","            min_val = np.min(param)\n","            max_val = np.max(param)\n","            param = np.round((param - min_val) / (max_val - min_val) * 255)\n","            param = np.uint8(param)\n","            custom_dict[name] = (min_val, max_val, param)\n","        else:\n","            custom_dict[name] = param\n","\n","    pickle.dump(custom_dict, open(fname, 'wb'))\n","\n","\n","def decode8(fname):\n","    params = pickle.load(open(fname, 'rb'))\n","    custom_dict = {}\n","    for (name, param) in params.items():\n","        if type(param) == tuple:\n","            min_val, max_val, param = param\n","            param = np.float64(param)\n","            param = (param / 255 * (max_val - min_val)) + min_val\n","            param = torch.tensor(param)\n","        else:\n","            param = torch.tensor(param)\n","\n","        custom_dict[name] = param\n","\n","    return custom_dict\n","\n","encode8(params, '8_bit_model.pkl')\n","print(f\"8-bit cost: {os.stat('8_bit_model.pkl').st_size} bytes.\")"],"execution_count":null,"outputs":[{"output_type":"stream","text":["8-bit cost: 268471 bytes.\n"],"name":"stdout"}]}]}